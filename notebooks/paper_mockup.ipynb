{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Mockup\n",
    "## Test the whole process, including fake human reviewers.\n",
    "- Generate a corpus of 3 AnalysisRuns with 3 hypotheses each\n",
    "- 6 Reviewers, 3 to impersonate human reviewers \n",
    "- ReviewPlan that applies the 6 reviewers to the 3 analysis runs\n",
    "- Generate ReviewSets and execute\n",
    "- For each Reviewer, gather the reviews and run create_ranking_vector\n",
    "- Plot the Reviewers and the (fake) human reviewers\n",
    "- Produce the heatmap comparing the reviewers\n",
    "- [next - significance analysis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parent directory and db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rudi/agent_evaluation/notebooks\n",
      "/Users/rudi/agent_evaluation\n",
      "['/Users/rudi/anaconda3/envs/agent_eval/lib/python311.zip', '/Users/rudi/anaconda3/envs/agent_eval/lib/python3.11', '/Users/rudi/anaconda3/envs/agent_eval/lib/python3.11/lib-dynload', '', '/Users/rudi/anaconda3/envs/agent_eval/lib/python3.11/site-packages', '/Users/rudi/agent_evaluation']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of the current script to the Python path\n",
    "cwd = os.getcwd()\n",
    "dirname = os.path.dirname(cwd)\n",
    "print(cwd)\n",
    "print(dirname)\n",
    "sys.path.append(dirname)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.analysis_plan import AnalysisPlan\n",
    "from services.analysisrunner import AnalysisRunner\n",
    "from models.review_plan import ReviewPlan\n",
    "from services.reviewrunner import ReviewRunner\n",
    "from app.sqlite_database import SqliteDatabase\n",
    "from app.config import load_database_config\n",
    "\n",
    "# Load the db connection details\n",
    "# db_type, uri, user, password = load_database_config(path='~/ae_config/test_config.ini')\n",
    "# self.db = Database(uri, db_type, user, password)\n",
    "\n",
    "_, database_uri, _, _ = load_database_config()\n",
    "db = SqliteDatabase(database_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate AnalysisRuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_plan_ids = [p1, p2, p3]\n",
    "analysis_runs = []\n",
    "for ap_id in analysis_plan_ids:\n",
    "    analysis_plan = AnalysisPlan.load(db, ap_id)\n",
    "    analysis_run = analysis_plan.generate_analysis_run()\n",
    "    analysis_runs.append(analysis_run)\n",
    "\n",
    "for analysis_run in analysis_runs:\n",
    "    runner = AnalysisRunner(db, analysis_run.object_id)\n",
    "    result = runner.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ReviewPlans, generate the ReviewSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_plan_ids = [\"review_plan_ad5c1fe8-dc76-4940-a938-bdfbd569f42d\"]\n",
    "review_sets = []\n",
    "for review_plan_id in review_plan_ids:\n",
    "    review_plan = ReviewPlan.load(db, review_plan_id)\n",
    "    # Generate an empty ReviewSet from the ReviewPlan\n",
    "    review_set = review_plan.generate_review_set()\n",
    "    review_sets.append(review_set)\n",
    "\n",
    "review_sets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ReviewSets\n",
    "Populate the ReviewSets with Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review_set in review_sets:\n",
    "    # Run the ReviewSet using a ReviewRunner\n",
    "    runner = ReviewRunner(db, review_set.object_id)\n",
    "    result = runner.run()\n",
    "\n",
    "review_sets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Reviewer judgment vectors from the Reviews in the ReviewSets\n",
    "The vectors correspond to the given ordered list of ReviewSets. They are not comparable otherwise.\n",
    "\n",
    "We create a datastructure in which each Reviewer is associated with its judgment vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.analysis import create_review_judgment_vector, create_judgment_vector\n",
    "from models.analyst import Analyst\n",
    "\n",
    "reviewer_judgment_vectors = {}\n",
    "\n",
    "# TODO: add error checking to be sure that the Reviewers match\n",
    "# across the ReviewSets\n",
    "for reviewer_id in review_sets[0].reviewer_ids:\n",
    "    reviewer = Analyst.load(reviewer_id)\n",
    "    vectors = []\n",
    "    \n",
    "    for review_set in review_sets:\n",
    "        vector = create_review_judgment_vector(review_set, reviewer)\n",
    "        vectors.append(vector)\n",
    "\n",
    "    reviewer_judgment_vectors[reviewer_id] = create_judgment_vector(vectors)\n",
    "\n",
    "    \n",
    "\n",
    "reviewer_judgment_vectors\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the judgment vectors\n",
    " - Label the points with the Reviewer names\n",
    " - The Reviewer names are prefixed with \"H.\", which is stripped off before labeling\n",
    " - Agents in red squares, Humans in blue circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.analysis import visualize_judgment_vectors\n",
    "\n",
    "visualize_judgment_vectors(reviewer_judgment_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Reviewer similarity heatmap\n",
    " - higher similarity is more red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.analysis import reviewer_similarity_heatmap\n",
    "\n",
    "reviewer_similarity_heatmap(reviewer_judgment_vectors)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
