{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Statistical Analysis\n",
    "## Using some of the agents as fake human reviewers.\n",
    "- Load one or more ReviewSets\n",
    "- For each Reviewer, gather the reviews and run create_ranking_vector\n",
    "- Plot the Reviewers and the (fake) human reviewers\n",
    "- Produce the heatmap comparing the reviewers\n",
    "- [next - significance analysis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parent directory and db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/idekeradmin/Dropbox/GitHub/agent_evaluation/notebooks\n",
      "/Users/idekeradmin/Dropbox/GitHub/agent_evaluation\n",
      "['/Users/idekeradmin/Dropbox/GitHub/agent_evaluation/notebooks', '/opt/anaconda3/lib/python311.zip', '/opt/anaconda3/lib/python3.11', '/opt/anaconda3/lib/python3.11/lib-dynload', '', '/Users/idekeradmin/.local/lib/python3.11/site-packages', '/opt/anaconda3/lib/python3.11/site-packages', '/opt/anaconda3/lib/python3.11/site-packages/aeosa', '/Users/idekeradmin/Dropbox/GitHub/agent_evaluation']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of the current script to the Python path\n",
    "cwd = os.getcwd()\n",
    "dirname = os.path.dirname(cwd)\n",
    "print(cwd)\n",
    "print(dirname)\n",
    "sys.path.append(dirname)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.analysis_plan import AnalysisPlan\n",
    "from services.analysisrunner import AnalysisRunner\n",
    "from models.review_plan import ReviewPlan\n",
    "from services.reviewrunner import ReviewRunner\n",
    "from app.sqlite_database import SqliteDatabase\n",
    "from app.config import load_database_config\n",
    "\n",
    "# Load the db connection details\n",
    "# db_type, uri, user, password = load_database_config(path='~/ae_config/test_config.ini')\n",
    "# self.db = Database(uri, db_type, user, password)\n",
    "\n",
    "_, database_uri, _, _ = load_database_config()\n",
    "db = SqliteDatabase(database_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate AnalysisRuns\n",
    "### Not doing this, change cell back to code if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysis_plan_ids = [p1, p2, p3]\n",
    "analysis_runs = []\n",
    "for ap_id in analysis_plan_ids:\n",
    "    analysis_plan = AnalysisPlan.load(db, ap_id)\n",
    "    analysis_run = analysis_plan.generate_analysis_run()\n",
    "    analysis_runs.append(analysis_run)\n",
    "\n",
    "for analysis_run in analysis_runs:\n",
    "    runner = AnalysisRunner(db, analysis_run.object_id)\n",
    "    result = runner.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ReviewPlans, generate the ReviewSets\n",
    "### Not doing this, change cell back to code if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review_plan_ids = [\"review_plan_ad5c1fe8-dc76-4940-a938-bdfbd569f42d\"]\n",
    "review_sets = []\n",
    "for review_plan_id in review_plan_ids:\n",
    "    review_plan = ReviewPlan.load(db, review_plan_id)\n",
    "    # Generate an empty ReviewSet from the ReviewPlan\n",
    "    review_set = review_plan.generate_review_set()\n",
    "    review_sets.append(review_set)\n",
    "\n",
    "review_sets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ReviewSets\n",
    "### Not doing this, change cell back to code if needed\n",
    "Populate the ReviewSets with Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for review_set in review_sets:\n",
    "    # Run the ReviewSet using a ReviewRunner\n",
    "    runner = ReviewRunner(db, review_set.object_id)\n",
    "    result = runner.run()\n",
    "\n",
    "review_sets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Reviewer judgment vectors from the Reviews in the ReviewSets\n",
    "The vectors correspond to the given ordered list of ReviewSets. They are not comparable otherwise.\n",
    "\n",
    "We create a datastructure in which each Reviewer is associated with its judgment vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from typing import Dict, Tuple\n",
    "from itertools import combinations\n",
    "from models.review import Review\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_review(db, review_set, reviewer_id):\n",
    "    for review_id in review_set.review_ids:\n",
    "        review = Review.load(db, review_id)\n",
    "        if review.analyst_id == reviewer_id:\n",
    "            return review\n",
    "    raise ValueError(\"Reviewer not in ReviewSet\")\n",
    "\n",
    "def create_review_judgment_vector(db, review_set=None, reviewer_id=None):\n",
    "    \"\"\"\n",
    "    Create a judgment vector for the Review \n",
    "    belonging to the Reviewer in the ReviewSet\n",
    "\n",
    "    Each ReviewSet is the result of one or more Reviewers judging\n",
    "    (assigning a partial ranking) the Hypothesis objects in an AnalysisRun, \n",
    "    as specified in the corresponding ReviewPlan\n",
    "\n",
    "    Each Review in the ReviewSet contains a partial ranking for each Hypothesis\n",
    "    in the Review. TODO: format example. There is one Review per Reviewer.\n",
    "    \n",
    "    The Hypotheses in the Review are identified according to their order in the \n",
    "    AnalysisRun, which is in turn specified by their order in the AnalysisPlan\n",
    "\n",
    "    The vector is in N dimensions in the judgment space where\n",
    "    N is the number of unique hypothesis vs. hypothesis comparisons.\n",
    "\n",
    "    Each comparison is represented as 1 | 0 | -1 based on: \n",
    "        A > B -> 1  (prefer A)\n",
    "        A = B -> 0  (no preference)\n",
    "        A < B -> -1 (prefer B)\n",
    "    \n",
    "    :param review_set: ReviewSet object\n",
    "    :return: NumPy array representing the judgment vector\n",
    "    \"\"\"\n",
    "    review = get_review(db, review_set, reviewer_id)\n",
    "\n",
    "    ranking_data = json.loads(review.ranking_data)\n",
    "\n",
    "    N = len(ranking_data[\"rankings\"])  # Number of Hypothesis objects in the ReviewSet\n",
    "\n",
    "    rankings = np.zeros(N, dtype=int) \n",
    "    for hypothesis_id, ranking in ranking_data[\"rankings\"].items():\n",
    "        order = int(ranking[\"order\"])\n",
    "        stars = int(ranking[\"stars\"])\n",
    "        rankings[order - 1] = stars\n",
    "    \n",
    "    # Create a vector long enough to hold the unique A-B comparisons,\n",
    "    # not including self comparisons\n",
    "    review_judgment_vector_length = (N * (N - 1) // 2)\n",
    "    review_judgment_vector = np.zeros(review_judgment_vector_length, dtype=np.int8)\n",
    "    \n",
    "    idx = 0\n",
    "    for i, j in combinations(range(N), 2):\n",
    "        if rankings[i] < rankings[j]:\n",
    "            review_judgment_vector[idx] = -1\n",
    "        elif rankings[i] > rankings[j]:\n",
    "            review_judgment_vector[idx] = 1\n",
    "        # If the hypotheses are tied, the value remains 0\n",
    "        idx += 1\n",
    "    \n",
    "    return review_judgment_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_judgment_vector(db, review_sets=None, reviewer_id=None):\n",
    "    # For a each ReviewSet, create a judgment\n",
    "    # vector for the specified Reviewer\n",
    "    #\n",
    "    # Each judgement_vector represents coordinates\n",
    "    # in a separate set of dimensions in the\n",
    "    # judgment space. \n",
    "    #\n",
    "    # We can therefore create a merged vector\n",
    "    # by simple concatenation.\n",
    "    #\n",
    "    # NOTE\n",
    "    # The judgment vectors for the reviewers are\n",
    "    # comparable ONLY if the ReviewSets \n",
    "    # have exactly the same Reviewers. Otherwise,\n",
    "    # the vectors will be of different lengths\n",
    "    # for different reviewers and the A-B\n",
    "    # comparisons will not align.\n",
    "    judgment_vector_list = []\n",
    "    review_jvecs = {}\n",
    "    for review_set in review_sets:\n",
    "        review_jvec = create_review_judgment_vector(db, review_set=review_set, reviewer_id=reviewer_id)\n",
    "        judgment_vector_list.append(review_jvec)\n",
    "        review_jvecs[reviewer_id] = review_jvec\n",
    "    return np.concatenate(judgment_vector_list), review_jvecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making jvec for reviewer: analyst_8148fd22-bdd8-4bda-910d-f7301f98a64d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 577, in _pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Review.__init__() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reviewer_id \u001b[38;5;129;01min\u001b[39;00m review_plan\u001b[38;5;241m.\u001b[39manalyst_ids:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaking jvec for reviewer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreviewer_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     judgment_vector, review_jvecs \u001b[38;5;241m=\u001b[39m create_judgment_vector(db, review_sets\u001b[38;5;241m=\u001b[39mreview_sets, reviewer_id\u001b[38;5;241m=\u001b[39mreviewer_id)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview jvecs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m jvec \u001b[38;5;129;01min\u001b[39;00m review_jvecs:\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mcreate_judgment_vector\u001b[0;34m(db, review_sets, reviewer_id)\u001b[0m\n\u001b[1;32m     20\u001b[0m review_jvecs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review_set \u001b[38;5;129;01min\u001b[39;00m review_sets:\n\u001b[0;32m---> 22\u001b[0m     review_jvec \u001b[38;5;241m=\u001b[39m create_review_judgment_vector(db, review_set\u001b[38;5;241m=\u001b[39mreview_set, reviewer_id\u001b[38;5;241m=\u001b[39mreviewer_id)\n\u001b[1;32m     23\u001b[0m     judgment_vector_list\u001b[38;5;241m.\u001b[39mappend(review_jvec)\n\u001b[1;32m     24\u001b[0m     review_jvecs[reviewer_id] \u001b[38;5;241m=\u001b[39m review_jvec\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mcreate_review_judgment_vector\u001b[0;34m(db, review_set, reviewer_id)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_review_judgment_vector\u001b[39m(db, review_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reviewer_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Create a judgment vector for the Review \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    belonging to the Reviewer in the ReviewSet\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    :return: NumPy array representing the judgment vector\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     review \u001b[38;5;241m=\u001b[39m get_review(db, review_set, reviewer_id)\n\u001b[1;32m     36\u001b[0m     ranking_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(review\u001b[38;5;241m.\u001b[39mranking_data)\n\u001b[1;32m     38\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ranking_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrankings\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# Number of Hypothesis objects in the ReviewSet\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mget_review\u001b[0;34m(db, review_set, reviewer_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_review\u001b[39m(db, review_set, reviewer_id):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m review_id \u001b[38;5;129;01min\u001b[39;00m review_set\u001b[38;5;241m.\u001b[39mreview_ids:\n\u001b[0;32m----> 3\u001b[0m         review \u001b[38;5;241m=\u001b[39m Review\u001b[38;5;241m.\u001b[39mload(db, review_id)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m review\u001b[38;5;241m.\u001b[39manalyst_id \u001b[38;5;241m==\u001b[39m reviewer_id:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m review\n",
      "File \u001b[0;32m~/Dropbox/GitHub/agent_evaluation/models/review.py:43\u001b[0m, in \u001b[0;36mReview.load\u001b[0;34m(cls, db, object_id)\u001b[0m\n\u001b[1;32m     41\u001b[0m properties, _ \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mload(object_id)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m properties:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(db, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mproperties)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Review.__init__() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "#from app.analysis import create_review_judgment_vector, create_judgment_vector\n",
    "from models.analyst import Analyst\n",
    "from models.review_set import ReviewSet\n",
    "\n",
    "review_set_ids = [\"review_set_718d6273-a001-4576-9beb-d2bc33f661df\"]\n",
    "review_sets = []\n",
    "for review_set_id in review_set_ids:\n",
    "    review_set = ReviewSet.load(db, review_set_id)\n",
    "    review_sets.append(review_set)\n",
    "\n",
    "reviewer_judgment_vectors = {}\n",
    "\n",
    "# We get the ReviewPlan for the first ReviewSet so that we can get the list of Reviewers\n",
    "# The list must be the same for all review sets - each Reviewer must see the same ReviewSets \n",
    "# TODO: add error checking to be sure that the Reviewers match across the ReviewSets\n",
    "review_plan = ReviewPlan.load(db, review_sets[0].review_plan_id)\n",
    "for reviewer_id in review_plan.analyst_ids:\n",
    "    print(f'making jvec for reviewer: {reviewer_id}')\n",
    "    judgment_vector, review_jvecs = create_judgment_vector(db, review_sets=review_sets, reviewer_id=reviewer_id)\n",
    "    print(\"review jvecs:\")\n",
    "    for jvec in review_jvecs:\n",
    "        print(jvec)\n",
    "    reviewer_judgment_vectors[reviewer_id] = {\"judgment_vector\": judgment_vector,\n",
    "                                               \"review_judgment_vectors\": review_jvecs}\n",
    "    \n",
    "\n",
    "reviewer_judgment_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the judgment vectors\n",
    " - Label the points with the Reviewer names\n",
    " - The Reviewer names are prefixed with \"H.\", which is stripped off before labeling\n",
    " - Agents in red squares, Humans in blue circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize_judgment_vectors\n\u001b[0;32m----> 3\u001b[0m visualize_judgment_vectors(reviewer_judgment_vectors)\n",
      "File \u001b[0;32m~/Dropbox/GitHub/agent_evaluation/app/analysis.py:184\u001b[0m, in \u001b[0;36mvisualize_judgment_vectors\u001b[0;34m(reviewer_data, plot_type, n_components, random_state, figsize)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid plot_type. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMAP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSNE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m reduced_data \u001b[38;5;241m=\u001b[39m reducer\u001b[38;5;241m.\u001b[39mfit_transform(all_reviewers)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[1;32m    187\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 462\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m    463\u001b[0m U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_full(X, n_components)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         )\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[1;32m    530\u001b[0m     )\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Center data\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "\n",
    "def visualize_judgment_vectors(reviewer_data: Dict[str, Dict], \n",
    "                               plot_type: str = 'PCA', \n",
    "                               n_components: int = 2,\n",
    "                               random_state: int = 42,\n",
    "                               figsize: Tuple[int, int] = (10, 8)):\n",
    "    \"\"\"\n",
    "    Visualize multiple reviewers in judgment space.\n",
    "    \n",
    "    :param reviewer_data: Dictionary of reviewer data\n",
    "    :param plot_type: Type of plot ('PCA', 'UMAP', or 'TSNE')\n",
    "    :param n_components: Number of components for dimensionality reduction\n",
    "    :param random_state: Random state for reproducibility\n",
    "    :param figsize: Figure size\n",
    "    \"\"\"\n",
    "    # Extract judgment vectors and labels\n",
    "    judgment_vectors = []\n",
    "    labels = []\n",
    "    n = 1\n",
    "    for reviewer_id, data in reviewer_data.items():\n",
    "        judgment_vectors.append(data['judgment_vector'])\n",
    "        if \"label\" in data and data['label'] is not None:\n",
    "            labels.append(data['label'])\n",
    "        else:\n",
    "            labels.append(f'label#{str(n)}')\n",
    "            n += 1\n",
    "\n",
    "    # Convert to numpy array\n",
    "    all_reviewers = np.vstack(judgment_vectors)\n",
    "\n",
    "    # Determine the number of components\n",
    "    n_samples, n_features = all_reviewers.shape\n",
    "    n_components = min(n_components, n_samples, n_features)\n",
    "    \n",
    "    # Perform dimensionality reduction\n",
    "    if plot_type == 'PCA':\n",
    "        reducer = PCA(n_components=n_components, random_state=random_state)\n",
    "    elif plot_type == 'UMAP':\n",
    "        reducer = umap.UMAP(n_components=n_components, random_state=random_state)\n",
    "    elif plot_type == 'TSNE':\n",
    "        reducer = TSNE(n_components=n_components, random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid plot_type. Choose 'PCA', 'UMAP', or 'TSNE'.\")\n",
    "    \n",
    "    try:\n",
    "        reduced_data = reducer.fit_transform(all_reviewers)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in dimensionality reduction: {e}\")\n",
    "        print(f\"Number of reviewers: {n_samples}, Number of features: {n_features}\")\n",
    "        return\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=figsize)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(set(labels))))\n",
    "    color_dict = {label: color for label, color in zip(set(labels), colors)}\n",
    "    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h', 'H', '+', 'x', 'd', '|', '_']\n",
    "    marker_dict = {label: marker for label, marker in zip(set(labels), markers)}\n",
    "    \n",
    "    for i, (x, y) in enumerate(reduced_data):\n",
    "        label = labels[i]\n",
    "        plt.scatter(x, y, \n",
    "                    c=[color_dict[label]], \n",
    "                    marker=marker_dict[label], \n",
    "                    label=label if label not in plt.gca().get_legend_handles_labels()[1] else \"\",\n",
    "                    alpha=0.7)\n",
    "    \n",
    "    plt.title(f\"Reviewers in {plot_type} Space\")\n",
    "    plt.xlabel(f\"{plot_type}1\")\n",
    "    plt.ylabel(f\"{plot_type}2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_judgment_vectors(reviewer_judgment_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Reviewer similarity heatmap\n",
    " - higher similarity is more red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reviewer_similarity_heatmap(reviewer_judgment_vectors, metric='cosine', method='average', figsize=(12, 10)):\n",
    "    \"\"\"\n",
    "    Create a similarity heatmap for judgment vectors with clustering.\n",
    "    \n",
    "    :param reviewer_judgment_vectors: dict where the keys are reviewer ids and the values are numpy vectors\n",
    "    :param judge_labels: List of labels for each reviewer\n",
    "    :param metric: Distance metric for similarity (default: 'cosine')\n",
    "    :param method: Linkage method for hierarchical clustering (default: 'average')\n",
    "    :param figsize: Figure size (width, height) in inches\n",
    "    \"\"\"\n",
    "\n",
    "    # 2D array where each row is a reviewer's vector\n",
    "    judgment_vectors = []\n",
    "    # List of reviewer labels\n",
    "    reviewer_labels = []\n",
    "\n",
    "    for reviewer, judgement_vector in reviewer_judgment_vectors:\n",
    "        judgment_vectors.append(judgement_vector)\n",
    "        reviewer_labels.append(reviewer.name)\n",
    "\n",
    "    # Compute pairwise distances\n",
    "    distances = pdist(judgment_vectors, metric=metric)\n",
    "    similarity_matrix = 1 - squareform(distances)  # Convert distances to similarities\n",
    "    \n",
    "    # Perform hierarchical clustering\n",
    "    linkage = hierarchy.linkage(distances, method=method)\n",
    "    \n",
    "    # Create a clustered heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.set_theme(font_scale=0.8)\n",
    "    \n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(h_neg=220, h_pos=10, as_cmap=True)\n",
    "    \n",
    "    # Create the heatmap\n",
    "    g = sns.clustermap(similarity_matrix,\n",
    "                       row_linkage=linkage,\n",
    "                       col_linkage=linkage,\n",
    "                       cmap=cmap,\n",
    "                       center=0,\n",
    "                       annot=True,\n",
    "                       fmt='.2f',\n",
    "                       xticklabels=reviewer_labels,\n",
    "                       yticklabels=reviewer_labels,\n",
    "                       figsize=figsize)\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.title(\"Reviewer Similarity Heatmap\", pad=50)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from app.analysis import reviewer_similarity_heatmap\n",
    "\n",
    "reviewer_similarity_heatmap(reviewer_judgment_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
