{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for creating agents programatically \n",
    "\n",
    "### set up parent directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/idekeradmin/Dropbox/GitHub/agent_evaluation/notebooks\n",
      "/Users/idekeradmin/Dropbox/GitHub/agent_evaluation\n",
      "['/Users/idekeradmin/Dropbox/GitHub/agent_evaluation/notebooks', '/opt/anaconda3/lib/python311.zip', '/opt/anaconda3/lib/python3.11', '/opt/anaconda3/lib/python3.11/lib-dynload', '', '/Users/idekeradmin/.local/lib/python3.11/site-packages', '/opt/anaconda3/lib/python3.11/site-packages', '/opt/anaconda3/lib/python3.11/site-packages/aeosa', '/Users/idekeradmin/Dropbox/GitHub/agent_evaluation', '/Users/idekeradmin/Dropbox/GitHub/agent_evaluation']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of the current script to the Python path\n",
    "cwd = os.getcwd()\n",
    "dirname = os.path.dirname(cwd)\n",
    "print(cwd)\n",
    "print(dirname)\n",
    "sys.path.append(dirname)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load database \n",
    "\n",
    "- make sure there is a ~/ae_config/config.ini file for all the configs, and ~/ae_database/ae_database.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.analysis_plan import AnalysisPlan\n",
    "from services.analysisrunner import AnalysisRunner\n",
    "from app.sqlite_database import SqliteDatabase\n",
    "from app.config import load_database_config\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the db connection details\n",
    "# db_type, uri, user, password = load_database_config(path='~/ae_config/test_config.ini')\n",
    "# self.db = Database(uri, db_type, user, password)\n",
    "\n",
    "_, database_uri, _, _ = load_database_config()\n",
    "db = SqliteDatabase(database_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the available LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llama-3.1-70b-versatile 2048/0.7': 'llm_a38b5b94-14d6-4216-b166-6f1515faa3a1',\n",
       " 'claude-3-haiku-20240307 2048/0.7': 'llm_23a5c740-4d9b-4839-8c0a-7fb6ccae1ff1',\n",
       " 'claude-3-5-sonnet-20240620 2048/0.7': 'llm_bb90988c-fa06-4a3a-99cc-81608fa8d1d7',\n",
       " 'gpt-4o-mini-2024-07-18 2048/0.7': 'llm_09620189-3486-4118-941c-7c674bc25657',\n",
       " 'mixtral-8x7b-32768 2048/0.7': 'llm_6e44f8e2-5089-40b1-ad37-db18f31f2b39',\n",
       " 'gpt-4o-2024-05-13 2048/0.7': 'llm_dc39023b-77bf-4d2f-a6a0-829ce9c3655d',\n",
       " 'llama-3.1-8b-instant 2048/0.7': 'llm_d8c65a1f-a3d9-4198-9a68-7dfb9e0b4510',\n",
       " 'gemini-1.5-flash-latest': 'llm_5ca276cc-d40a-467f-8bd6-188307d3da62'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_specs = db.find(\"llm\")\n",
    "llm_mappings = {}\n",
    "for llm_spec in llm_specs:\n",
    "    llm_id = llm_spec[\"object_id\"]\n",
    "    llm_properties = llm_spec[\"properties\"]\n",
    "    llm_name = llm_properties[\"name\"]\n",
    "    llm_mappings[llm_name] = llm_id\n",
    "\n",
    "llm_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyst_context_gradStudent_exam_0815\n",
      "analyst_two_hypotheses\n",
      "analyst_context_assistant_with_biocontext_0815\n",
      "analyst_two_hypotheses_KG\n",
      "analyst_context_assistant_0815\n",
      "analyst_context_instructor_answer_0815\n",
      "analyst_context_GSR_newproject_0815\n",
      "context_gsr_1st_yr_ml_0814\n",
      "context_gsr_0814\n",
      "context_pi_0814\n",
      "context_cell_editor\n",
      "reviewer_reflect_0814\n",
      "reviewer_0814\n",
      "reviewer_cot_multi_criteria\n",
      "reviewer_cot_reflect_0814\n",
      "reviewer_cot_0814\n",
      "reviewer_cot_reflect_novelty_0814\n",
      "gs_cot\n",
      "analyst_kg_brief_0821\n",
      "analyst_cot_kg_brief_0821\n",
      "analyst_cot_review_brief_0821\n",
      "analyst_brief_0821\n",
      "analyst_minimal_0814\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "dirname = os.path.dirname(cwd)\n",
    "\n",
    "prompt_directory = (os.path.join(dirname, \"prompts\"))\n",
    "\n",
    "def read_text_files(directory):\n",
    "    file_contents = {}\n",
    "    \n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Check if the file is a text file\n",
    "            if filename.endswith('.txt'):\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(root, filename)\n",
    "                \n",
    "                # Get the filename without extension\n",
    "                file_key = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # Read the contents of the file\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        content = file.read()\n",
    "                        file_contents[file_key] = content\n",
    "                except IOError as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "    \n",
    "    return file_contents\n",
    "\n",
    "prompts = read_text_files(prompt_directory)\n",
    "\n",
    "for name, text in prompts.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Analyst Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gsr_cot_review_c_3_5': <models.agent.Agent at 0x17d5340d0>,\n",
       " 'gsr_cot_review_4o_mini': <models.agent.Agent at 0x17d51c250>,\n",
       " 'gsr_cot_kg_3_5': <models.agent.Agent at 0x17d51e150>,\n",
       " 'gsr_cot_kg_4o_mini': <models.agent.Agent at 0x17c3b0e10>,\n",
       " 'gsr_kg_3_5': <models.agent.Agent at 0x17c3b15d0>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.agent import Agent\n",
    "\n",
    "llm_claude_3_5 = llm_mappings[\"claude-3-5-sonnet-20240620 2048/0.7\"]\n",
    "llm_gpt_4o_mini = llm_mappings[\"gpt-4o-mini-2024-07-18 2048/0.7\"]\n",
    "\n",
    "analyst_specs = {\n",
    "    \"gsr_cot_review_c_3_5\":{\n",
    "        \"llm_id\": llm_claude_3_5,\n",
    "        \"prompt_template\": prompts[\"analyst_cot_review_brief_0821\"],\n",
    "        \"context\": prompts[\"context_gsr_0814\"],\n",
    "        \"description\": \"\"\n",
    "    },\n",
    "    \"gsr_cot_review_4o_mini\":{\n",
    "        \"llm_id\": llm_gpt_4o_mini,\n",
    "        \"prompt_template\": prompts[\"analyst_cot_review_brief_0821\"],\n",
    "        \"context\": prompts[\"context_gsr_0814\"],\n",
    "        \"description\": \"\"\n",
    "    },\n",
    "    \"gsr_cot_kg_3_5\":{\n",
    "        \"llm_id\": llm_claude_3_5,\n",
    "        \"prompt_template\": prompts[\"analyst_cot_kg_brief_0821\"],\n",
    "        \"context\": prompts[\"context_gsr_0814\"],\n",
    "        \"description\": \"\"\n",
    "    },\n",
    "    \"gsr_cot_kg_4o_mini\":{\n",
    "        \"llm_id\": llm_gpt_4o_mini,\n",
    "        \"prompt_template\": prompts[\"analyst_cot_kg_brief_0821\"],\n",
    "        \"context\": prompts[\"context_gsr_0814\"],\n",
    "        \"description\": \"\"\n",
    "    },\n",
    "    \"gsr_kg_3_5\":{\n",
    "        \"llm_id\": llm_claude_3_5,\n",
    "        \"prompt_template\": prompts[\"analyst_kg_brief_0821\"],\n",
    "        \"context\": prompts[\"context_gsr_0814\"],\n",
    "        \"description\": \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "analysts = {}\n",
    "\n",
    "for name, spec in analyst_specs.items():\n",
    "    analysts[name] = Agent.create(db, \n",
    "                                  spec[\"llm_id\"], \n",
    "                                  spec[\"context\"],\n",
    "                                  spec[\"prompt_template\"],\n",
    "                                  name=name,\n",
    "                                  description=spec.get('description'))\n",
    "    \n",
    "analysts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Reviewer Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rev_cot_reflect_novelty_3_5': <models.agent.Agent at 0x17d51c410>,\n",
       " 'rev_cot_reflect_3_5': <models.agent.Agent at 0x17d51c790>,\n",
       " 'rev_cot_reflect_novelty_4o_mini': <models.agent.Agent at 0x17d51c950>,\n",
       " 'rev_cot_reflect_4o_mini': <models.agent.Agent at 0x17d51cb10>,\n",
       " 'rev_cot_3_5': <models.agent.Agent at 0x17d51cd10>,\n",
       " 'rev_cot_4o_mini': <models.agent.Agent at 0x17d51cf10>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from models.agent import Agent\n",
    "\n",
    "pi_context = prompts[\"context_pi_0814\"]\n",
    "reviewer_specs = {\n",
    "    \"rev_cot_reflect_novelty_3_5\":{\n",
    "        \"llm_id\": llm_claude_3_5,\n",
    "        \"prompt_template\": prompts[\"reviewer_cot_reflect_novelty_0814\"],\n",
    "        \"context\": pi_context,\n",
    "        \"description\": \"PI reviewer preferring novelty, chain of thought, and reflection\"\n",
    "    },\n",
    "    \"rev_cot_reflect_3_5\":{\n",
    "        \"llm_id\": llm_claude_3_5,\n",
    "        \"prompt_template\": prompts[\"reviewer_cot_reflect_0814\"],\n",
    "        \"context\": pi_context,\n",
    "        \"description\": \"PI reviewer using chain of thought and reflection\"\n",
    "    },\n",
    "    \"rev_cot_reflect_novelty_4o_mini\":{\n",
    "        \"llm_id\": llm_gpt_4o_mini,\n",
    "        \"prompt_template\": prompts[\"reviewer_cot_reflect_novelty_0814\"],\n",
    "        \"context\": pi_context,\n",
    "        \"description\": \"PI reviewer preferring novelty, chain of thought, and reflection\"\n",
    "    },\n",
    "    \"rev_cot_reflect_4o_mini\":{\n",
    "        \"llm_id\": llm_gpt_4o_mini,\n",
    "        \"prompt_template\": prompts[\"reviewer_cot_reflect_0814\"],\n",
    "        \"context\": pi_context,\n",
    "        \"description\": \"PI reviewer using chain of thought and reflection\"\n",
    "    },\n",
    "    \"rev_cot_3_5\":{\n",
    "        \"llm_id\": llm_claude_3_5,\n",
    "        \"prompt_template\": prompts[\"reviewer_cot_0814\"],\n",
    "        \"context\": pi_context,\n",
    "        \"description\": \"PI reviewer, chain of thought\"\n",
    "    },\n",
    "    \"rev_cot_4o_mini\":{\n",
    "        \"llm_id\": llm_gpt_4o_mini,\n",
    "        \"prompt_template\": prompts[\"reviewer_cot_0814\"],\n",
    "        \"context\": pi_context,\n",
    "        \"description\": \"PI reviewer, chain of thought\"\n",
    "    }\n",
    "}\n",
    "\n",
    "reviewers = {}\n",
    "\n",
    "for name, spec in reviewer_specs.items():\n",
    "    reviewers[name] = Agent.create(db, \n",
    "                                  spec[\"llm_id\"], \n",
    "                                  spec[\"context\"],\n",
    "                                  spec[\"prompt_template\"],\n",
    "                                  name=name,\n",
    "                                  description=spec.get('description'))\n",
    "    \n",
    "reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new analysis plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new analysis run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nanalysis_run = analysis_plan.generate_analysis_run(biological_context=\"Chromatin remodelling and transcriptional regulation (or Transcriptional regulation and chromatin remodelling)\")\\nprint(analysis_run.object_id)\\nprint(vars(analysis_run))\\n\\nrunner = AnalysisRunner(db, analysis_run.object_id)\\nresult = runner.run()\\nprint(result)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "analysis_run = analysis_plan.generate_analysis_run(biological_context=\"Chromatin remodelling and transcriptional regulation (or Transcriptional regulation and chromatin remodelling)\")\n",
    "print(analysis_run.object_id)\n",
    "print(vars(analysis_run))\n",
    "\n",
    "runner = AnalysisRunner(db, analysis_run.object_id)\n",
    "result = runner.run()\n",
    "print(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhypotheses = db.load(analysis_run.object_id)[0]['hypothesis_ids']\\nhypotheses\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hypotheses = db.load(analysis_run.object_id)[0]['hypothesis_ids']\n",
    "hypotheses\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom models.hypothesis import Hypothesis\\n%reload_ext autoreload\\n%autoreload 2\\n\\nfor hypothesis_id in hypotheses:\\n    hypothesis = Hypothesis.load(db, hypothesis_id)\\n    # print(hypothesis_id)\\n    print(hypothesis.object_id)\\n    print(hypothesis.hypothesis_text)\\n    print(hypothesis.full_prompt)\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from models.hypothesis import Hypothesis\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "for hypothesis_id in hypotheses:\n",
    "    hypothesis = Hypothesis.load(db, hypothesis_id)\n",
    "    # print(hypothesis_id)\n",
    "    print(hypothesis.object_id)\n",
    "    print(hypothesis.hypothesis_text)\n",
    "    print(hypothesis.full_prompt)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
